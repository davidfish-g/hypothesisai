# HypothesisAI - AI Hypothesis Evaluation Platform

A web-based platform for domain experts to evaluate AI-generated scientific hypotheses, creating a leaderboard for model performance and generating a high-quality, labeled dataset.

## Features

- Expert authentication via Google Scholar
- Domain-specific hypothesis evaluation
- Structured evaluation criteria (plausibility, novelty, testability)
- Model performance leaderboards
- Dataset generation for future training
- Reviewer reliability tracking

## Tech Stack

- Next.js 14 (App Router)
- TypeScript
- Tailwind CSS
- Prisma (Database ORM)
- NextAuth.js (Authentication)
- PostgreSQL (Database)

## Getting Started

1. Clone the repository
2. Install dependencies:
   ```bash
   npm install
   ```
3. Set up environment variables:
   ```bash
   cp .env.example .env.local
   ```
4. Set up the database:
   ```bash
   npx prisma generate
   npx prisma db push
   ```
5. Run the development server:
   ```bash
   npm run dev
   ```

## Project Structure

```
hypothesisai/
├── app/                    # Next.js app directory
│   ├── api/               # API routes
│   ├── auth/              # Authentication pages
│   ├── dashboard/         # Expert dashboard
│   ├── evaluate/          # Hypothesis evaluation
│   └── leaderboard/       # Model performance leaderboard
├── components/            # Reusable components
├── lib/                   # Utility functions and configurations
├── prisma/               # Database schema and migrations
└── public/               # Static assets
```

## Contributing

Contributions are welcome! Please read our contributing guidelines before submitting pull requests.

## License

MIT License